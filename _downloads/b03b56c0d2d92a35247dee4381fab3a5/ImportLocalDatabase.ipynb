{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Import from Local DataBase\n\nThis Tutorial illustrates how to import waveform data from a local database\nof continuous waveforms into PyGLImER.\n\nAs we don't have actual offline data available, we will download some\ncontinuous data from two stations:\nstation IU-HRV ([Adam Dziewonski\nObservatory](http://www.seismology.harvard.edu/hrv.html)) and the Dutch\nstation NL-HGN.\n\nThis data will then be sliced into times, when arrivals from teleseismic\nevents are expected, which PyGLiMER determines in a previous step.\n\n## Downloading Event Catalogue & Feed in offline data\n\nHere, we will again use the :class:`pyglimer.waveform.request.Request`\nclass. The first method from this class that we are going to use is the\ndownload event catalog public method\n:func:`pyglimer.waveform.request.Request.download_evtcat`, to get a set\nof events that contains all wanted earthquakes. This method is launched\nautomatically upon initialization. (Same as in the download tutorials)\n\nTo initialize said `class` we set up a parameter dictionary, with all the\nneeded information. Let's look at the expected information:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# sphinx_gallery_thumbnail_number = 1\n# sphinx_gallery_dummy_images = 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "First let's get a path where to create the data.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Some needed Imports\nimport os\nfrom typing import List\nfrom obspy import UTCDateTime, read, read_inventory\nimport obspy\nfrom pyglimer.waveform.request import Request\n\n# Get notebook path for future reference of the database:\ntry: db_base_path = ipynb_path\nexcept NameError:\n    try: db_base_path = os.path.dirname(os.path.realpath(__file__))\n    except NameError: db_base_path = os.getcwd()\n\n# Define file locations\nproj_dir = os.path.join(db_base_path, 'tmp', 'database_sac_import')\n\n\nrequest_dict = {\n    # Necessary arguments\n    'proj_dir': proj_dir,\n    'raw_subdir': os.path.join('waveforms', 'raw'),# Directory of the waveforms\n    'prepro_subdir': os.path.join('waveforms', 'preprocessed'),  # Directory of the preprocessed waveforms\n    'rf_subdir': os.path.join('waveforms', 'RF'),  # Directory of the receiver functions\n    'statloc_subdir': 'stations', # Directory stations\n    'evt_subdir': 'events',       # Directory of the events\n    'log_subdir': 'log',          # Directory for the logs\n    'loglvl': 'DEBUG',          # logging level, for more info use 'INFO' or 'DEBUG'\n    'format': 'sac',              # Format to save database in\n    \"phase\": \"P\",                 # 'P' or 'S' receiver functions\n    \"rot\": \"RTZ\",                 # Coordinate system to rotate to\n    \"deconmeth\": \"waterlevel\",    # Deconvolution method\n    \"starttime\": UTCDateTime(2021, 1, 10, 3, 0, 0), # Starttime of your data.\n    \"endtime\": UTCDateTime(2021, 1, 10, 5, 0, 0), # Endtimetime of your data\n    # kwargs below\n    \"pol\": 'v',                   # Source wavelet polaristion. Def. \"v\" --> SV\n    \"minmag\": 5.0,                # Earthquake minimum magnitude. Def. 5.5\n    \"event_coords\": None,         # Specific event?. Def. None\n    \"evtcat\": None,               # If you have already downloaded a set of\n                                  # events previously, you can use them here\n}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now that all parameters are in place, let's initialize the\n:class:`pyglimer.waveform.request.Request`\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Initializing the Request class and downloading the data\nR = Request(**request_dict)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The initialization will look for all events for which data is available. To\nsee whether the events make sense we plot a map of the events:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\nfrom pyglimer.plot.plot_utils import plot_catalog\nfrom pyglimer.plot.plot_utils import set_mpl_params\n\n# Setting plotting parameters\nset_mpl_params()\n\n# Plotting the catalog\nplot_catalog(R.evtcat)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can also quickly check how many events we gathered.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(f\"There are {len(R.evtcat)} available events\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Preliminary steps\n\nThis will be the most complex step because it requires you to write two\nfunctions: 1. A function that yields Obspy Streams. 2. A function that yields\nobspy inventories.\n\n***WARNING:*** both have to yield information for the same station. So both\nGenerators also need to have the same length.\n\nThese functions could for example look like this:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def yield_st_dummy(list_of_waveform_files: List[os.PathLike]):\n    for file in list_of_waveform_files:\n        yield obspy.read(file)\n\n\ndef yield_inventory_dummy(list_of_station_files: List[os.PathLike]):\n    for file in list_of_station_files:\n        yield obspy.read_inventory(file)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "***NOTE:*** This also requires you to convert/compile your information\nInto formats that obspy can read.\nTo create StationXMLs follow the following tutorial:\n[](https://docs.obspy.org/tutorial/code_snippets/stationxml_file_from_scratch.html)\nThe StationXML needs to contain the following information:\n1. Network and Station Code\n2. Latitude, Longitude, and Elevation\n3. Azimuth of Channel/Location to do the Rotation.\n4. (Optional/if you set remove_response=True) Station response information.\n\nThe header of the traces need to contain the following:\n1. sampling_rate\n2. start_time, end_time\n3. Network, Station, and Channel Code (Location code arbitrary)\nTo convert seismic data from unusual formats to mseed or sac, we recommend\nusing PyROCKO or obspy.\n\nWe will use two hours of data that come with PyGLImER\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def yield_st():\n    static = os.path.join(\n        db_base_path, 'static_data', 'database_sac', 'waveforms', 'local_db')\n    networks = ['IU']\n    stations = ['HRV']\n    for net, stat in zip(networks, stations):\n        st = read(os.path.join(static, net, stat, 'hrv10.mseed'))\n        yield st\n\n\ndef yield_inv():\n    static = os.path.join(\n        db_base_path, 'static_data', 'database_sac', 'waveforms', 'local_db')\n    networks = ['IU']\n    stations = ['HRV']\n    for net, stat in zip(networks, stations):\n        st = read_inventory(os.path.join(static, net, stat, 'hrv_stat.xml'))\n        yield st"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Import waveform data and station information\n\nThe hard part is done! The actual import into PyGLImER is easy now:\nTo do so, we use the public method of `Request`: `import_database()`\nThis method will do the following:\n1. Find times with teleseismic arrivals of our desired phase.\n2. Slice time windows around this arrivals.\n3. Do a first fast preprocessing.\n4. Save Traces and station information in desired `format` (mseed or asdf)\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "R.import_database(yield_st, yield_inv)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's just check how many teleseismic arrivals were found in this one week.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from glob import glob\n\n# Path to the where the miniseeds are stored\ndata_storage = os.path.join(\n    proj_dir, 'waveforms', 'raw', 'P', '**', '*.mseed')\n\n# Print output\nprint(f\"Number of found teleseismic arrivals: {len(glob(data_storage))}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "***NOTE*** From here on, the steps are identical to the download tutorials\nThe final step to get you receiver function data is the preprocessing. \nAlthough it is hidden in a single function, which\nis :func:`pyglimer.waveform.request.Request.preprocess`\nA lot of decisions are being made:\n\nProcessing steps:\n1. Clips waveform to the right length (tz before and ta after theorethical \narrival.)\n2. Demean & Detrend\n3. Tapering\n4. Remove Instrument response, convert to velocity &\nsimulate havard station\n5. Rotation to NEZ and, subsequently, to RTZ.\n6. Compute SNR for highpass filtered waveforms (highpass f defined in \nqc.lowco) If SNR lower than in qc.SNR_criteria for all filters, rejects \nwaveform.\n7. Write finished and filtered waveforms to folder\nspecified in qc.outputloc.\n8. Write info file with shelf containing station,\nevent and waveform information.\n9. (Optional) If we had chosen a different coordinate system in ``rot``\nthan RTZ, it would now cast the preprocessed waveforms information\nthat very coordinate system.\n10. Deconvolution with method ``deconmeth`` from our dict is perfomed.\n\nIt again uses the request class to perform this. The ``if __name__ ...``\nexpression is needed for running this examples\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "R.preprocess(hc_filt=1.5, client='single')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## First Receiver functions\n\nThe following few section show how to plot \n\n1. Single raw RFs\n2. A set of raw RFs\n3. A move-out corrected RF\n4. A set of move-out corrected RFs\n\n\n### Read the IU-HRV receiver functions as a Receiver function stream\n\nLet's read a receiver function set and see what it's all about! \n(i.e. let's look at what data a Receiver function trace contains\nand how we can use it!)\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from pyglimer.rf.create import read_rf\n\npath_to_rf = os.path.join(proj_dir, 'waveforms','RF','P','*','*','*.sac')\nrfstream = read_rf(path_to_rf)\n\nprint(f\"Number of RFs: {len(rfstream)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "PyGLImER is based on Obspy, but to handle RFs we need some more attributes: \n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from pprint import pprint\n\nrftrace = rfstream[0]\npprint(rftrace.stats)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## First Receiver function plots\n\nIf the Receiver functions haven't been further processed,\nthey are plotted as a function of time. A single receiver\nfunction in the stream will be plotted as function of time\nonly. A full stream can make use of the distance measure saved\nin the sac-header and plot an entire section as a function of\ntime and epicentral distance.\n\n### Plot single RF\n\nBelow we show how to plot the receiver function\nas a function of time, and the clean option, which plots\nthe receiver function without any axes or text.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from pyglimer.plot.plot_utils import set_mpl_params\n\n# Plot RF\nrftrace.plot()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's zoom into the first 20 seconds (~200km)\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "rftrace.plot(lim=[0, 20])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Plot RF section\n\nSince we have an entire stream of receiver functions at hand,\nwe can plot a section\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "rfstream.plot(scalingfactor=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Similar to the single RF plot we can provide time and \nepicentral distance limits:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "timelimits = (0, 20)  # seconds  \nepilimits = (32, 36)  # epicentral distance\nrfstream.plot(\n    scalingfactor=0.25, lim=timelimits, epilimits=epilimits,\n    linewidth=0.75)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "By increasing the scaling factor and removing the plotted lines, we can\nalready see trends:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "rfstream.plot(\n    scalingfactor=0.5, lim=timelimits, epilimits=epilimits, \n    line=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "As simple as that you can create your own receiver functions with \njust a single smalle script.\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}